services:
  # DeepSeek OCR - Model Server (vLLM)
  deepseek-ocr-vllm:
    build:
      context: ./deepseek-ocr-service
      dockerfile: Dockerfile.vllm
    ports:
      - "8101:8101"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./.cache/huggingface:/root/.cache/huggingface
    # Optimized to 0.45 to share GPU with Hunyuan OCR
    command: vllm serve deepseek-ai/DeepSeek-OCR --logits_processors vllm.model_executor.models.deepseek_ocr:NGramPerReqLogitsProcessor --no-enable-prefix-caching --mm-processor-cache-gb 0 --port 8101 --trust-remote-code --gpu-memory-utilization 0.45
    restart: unless-stopped

  # DeepSeek OCR - API Service (FastAPI)
  deepseek-ocr-api:
    build:
      context: ./deepseek-ocr-service
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    environment:
      - VLLM_URL=http://deepseek-ocr-vllm:8101/v1
    depends_on:
      - deepseek-ocr-vllm
    restart: unless-stopped

  # İflas OCR Pipeline - API Service (OpenAI + DeepSeek OCR)
  iflas-pipeline-api:
    build:
      context: ./pipelines/openai-iflas-pipeline
      dockerfile: Dockerfile
    ports:
      - "8003:8003"
    environment:
      - DEEPSEEK_OCR_URL=http://deepseek-ocr-api:8001/api/v1/ocr
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
    depends_on:
      - deepseek-ocr-api
    restart: unless-stopped

  # MBR Künye Pipeline - API Service (OpenAI + DeepSeek OCR)
  mbr-kunye-pipeline:
    build:
      context: ./pipelines/mbr-kunye-pipeline
      dockerfile: Dockerfile
    ports:
      - "8005:8005"
    environment:
      - DEEPSEEK_OCR_URL=http://deepseek-ocr-api:8001/api/v1/ocr
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
    depends_on:
      - deepseek-ocr-api
    restart: unless-stopped

  # Local Turkish-Gemma LLM - API Service (DISABLED)
  local-llm-api:
    build:
      context: ./local-llm-service
      dockerfile: Dockerfile
    ports:
      - "8004:8004"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./.cache/huggingface:/root/.cache/huggingface
    restart: unless-stopped
    profiles:
      - disabled  # This service is disabled by default

  # Frontend - Web UI (React + Nginx)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "80:80"
    depends_on:
      - deepseek-ocr-api
      - iflas-pipeline-api
    restart: unless-stopped
