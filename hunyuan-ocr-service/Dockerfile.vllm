FROM pytorch/pytorch:2.4.0-cuda12.1-cudnn9-devel

# Set working directory
WORKDIR /workspace

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Install vLLM NIGHTLY build (required for HunyuanOCR support)
RUN pip install --no-cache-dir -U vllm --pre --extra-index-url https://wheels.vllm.ai/nightly

# Install transformers and other dependencies
RUN pip install --no-cache-dir transformers pillow accelerate

# Pre-download the model tokenizer and processor
RUN python -c "from transformers import AutoTokenizer, AutoProcessor; \
    AutoTokenizer.from_pretrained('tencent/HunyuanOCR', trust_remote_code=True); \
    AutoProcessor.from_pretrained('tencent/HunyuanOCR', trust_remote_code=True)"

# Expose vLLM port
EXPOSE 8102

# Start vLLM server with HunyuanOCR specific parameters
CMD ["vllm", "serve", "tencent/HunyuanOCR", \
     "--host", "0.0.0.0", \
     "--port", "8102", \
     "--no-enable-prefix-caching", \
     "--mm-processor-cache-gb", "0", \
     "--gpu-memory-utilization", "0.45"]
